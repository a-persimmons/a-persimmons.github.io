[{"content":" 在当今快速发展的技术环境中，AI正在变革各行各业并推动创新，理解AI性能指标的复杂性至关重要。过去许多AI模型需要在云端运行。当我们走向由终端侧生成式AI处理定义的未来时，我们必须能够评估计算平台可运行AI模型的性能、准确性和效率。如今，TOPS(每秒万亿次运算)是衡量处理器AI性能的主要方式之一。TOPS是基于处理器所需的架构和频率，衡量处理器潜在AI推理峰值性能的方法，比如神经网络处理器(NPU)。\nNPU是什么？\n在深入探讨TOPS的具体内容之前，让我们先看看NPU的重要性。对于终端侧AI处理，NPU在提高效率、为个人用户和企业提供创新的应用体验方面发挥着关键作用。评估这些专用处理器的性能需要全面了解其能力背后的关键指标。\nNPU的演进改变了人们处理计算的方式。传统上，CPU负责执行AI算法。随着对处理性能的需求飙升，专用NPU应运而生，成为处理AI相关软件应用的专用解决方案。NPU旨在高效处理AI任务所需的复杂数学计算，提供出色的效率、性能和能效。\nAI TOPS是什么？\nTOPS作为展示处理器计算能力的指标，是衡量NPU性能的核心。\nTOPS通过以万亿单位测量一秒钟内执行的运算（加法、乘法等）次数来量化NPU处理能力。 这种标准化测量方式非常明确地显示了NPU的性能，可作为比较不同处理器和架构AI性能的关键指标。因为TOPS是针对NPU的基础性能指标，探索TOPS的计算参数以及它们如何决定性能至关重要，这有助于更深入地了解NPU的能力。\n乘法累加(MAC)运算执行AI工作负载中的核心数学公式。矩阵乘法由两类基础运算组成：累加器的乘法和加法。例如，一个MAC单元可在每个时钟周期内运行两类基础运算各一次，意味着它在每个时钟周期内执行两个运算。一个给定的NPU有一定数量的MAC单元，能够在不同精度级别进行运算，这取决于NPU架构。\n频率决定NPU及其MAC单元（以及CPU或GPU）运算的时钟速度（或每秒周期数），直接影响整体性能。更高的频率允许在单位时间内执行更多运算，从而提高处理速度。但是，提高频率也会导致更高功耗和发热，影响电池续航和用户体验。处理器TOPS计算通常使用峰值运行频率。\n精度指计算的颗粒度，通常精度越高模型准确性就越高，需要的计算强度也越高。最常见的高精度AI模型为32位和16位浮点精度，而速度更快的低精度低功耗模型通常使用8位和4位整数精度。当前行业标准为以INT8精度评估AI推理性能TOPS。\n计算TOPS要从计算OPS开始，OPS等于MAC单元数乘以运行频率的两倍。TOPS数量是OPS除以一万亿的值，将公式更简单地列出，即：\nTOPS = 2×MAC单元数×频率/1万亿。 TOPS和实际性能\n尽管TOPS提供了探索NPU能力的重要信息，我们仍必须将理论指标和实际应用联系起来。\n毕竟，仅仅有高TOPS值并不能保证最佳的AI性能；各种因素协同作用的结果才能真正决定NPU实力。 因此评估NPU性能时要考虑内存带宽、软件优化和系统集成等方面的因素。基准测试可以帮助我们超越数字，了解NPU在实际场景中的表现，其中时延、吞吐量和能效尤为重要。\nProcyon AI基准测试使用真实工作负载来帮助将理论性的TOPS评估转化为用户在使用AI推理的真实应用中对响应和处理能力的预期。它以多个精度运行六个模型，提供NPU不同性能表现的详细洞察。类似模型在生产力、媒体、创作者和其他应用中越来越常见。在Procyon AI和其他基准测试中有更快的性能表现，与实现更快推理和更好用户体验息息相关。\n为此，分析实际性能可以为NPU的能力和局限性提供宝贵洞察。必须从可行性和实用性角度检验性能指标。\n根据用户需求评估NPU性能\n应对快速变化的NPU性能评估领域或许会让人望而生畏，但随着数字化转型（尤其是在AI领域）持续快速发展，深入了解TOPS对行业和个人来说都很重要。\n最终，选择合适的系统级芯片(SoC)取决于用户、客户或组织的工作负载和优先级，而这一决策很可能需要取决于SoC中的NPU。\n无论用户是优先考虑原始算力、能效还是模型准确度，骁龙X系列平台面向笔记本电脑，配备高达45TOPS的NPU，能够强力赋能PC，并将实际可用的AI体验引入用户的工作流程。\n参考 深入了解面向计算的骁龙AI\n面向边缘终端优化生成式AI (qualcomm.cn)\n","permalink":"http://localhost:1313/posts/ai%E4%B8%ADtops%E5%92%8Cnpu%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E6%8C%87%E5%8D%97/","summary":"解释TOPS是什么","title":"AI中TOPS和NPU性能指标指南"},{"content":" 通过实际示例深入了解 CloudWeGo 的 Kitex，其高性能和可扩展性重新定义了微服务卓越标准。\n[译]：https://www.cloudwego.io/blog/2024/02/21/delving-deeper-enriching-microservices-with-golang-with-cloudwego/\n如果存在一个 RPC 框架，它不仅提供高性能和可扩展性，还拥有一套强大的功能和繁荣的社区支持，那会怎样？\nCloudWeGo，一个由字节跳动开发并开源的高性能可扩展 Golang 和 Rust RPC 框架，因其完美契合需求而引起了我的注意。\nCloudWeGo 与其他 RPC 框架对比 尽管 gRPC 和 Apache Thrift 为微服务架构提供了良好的支持，但 CloudWeGo 凭借其先进特性和性能指标，脱颖而出，成为未来有前景的开源解决方案。\nCloudWeGo基于 Golang 和 Rust 打造，适应现代开发环境，提供先进功能与卓越性能指标。性能测试表明，Kitex 在 QPS 和延迟方面超越 gRPC 四倍以上，QPS 和延迟的吞吐量提升 51%至 70%。\n这为开发者提供了一个工具，它不仅满足了现代微服务的性能要求，而且明显超越了这些要求。让我们深入探讨一些具体用例，以理解 CloudWeGo 的潜力。\nBookinfo：《交通处理的故事》 考虑 Bookinfo 这一 Istio 提供的示例应用，通过 CloudWeGo 的 Kitex 进行重写，以获得更卓越的性能和可扩展性。\n此用例展示了高流量服务如何显著受益于 CloudWeGo 的性能承诺。此次集成还展示了在流量处理和性能方面，CloudWeGo 如何超越传统的 Istio 服务网格。\n借助 Kitex 和 Hertz 处理流量重定向，Bookinfo 项目能够高效管理高流量，确保快速响应并提供更佳的用户体验。\nimport ( \u0026#34;github.com/cloudwego/kitex/server\u0026#34; ) func main() { svr := echo.NewServer(new(EchoImpl), server.WithName(\u0026#34;echo\u0026#34;)) listener, _ := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8888\u0026#34;) svr.Serve(listener) } 上述代码片段是一个简化的示例，展示了如何使用 Kitex 重写 Bookinfo 项目以获得更佳性能。\nEasy Note：简约之魔法 CloudWeGo 在简化复杂任务方面的承诺在 Easy Note 项目中得到了体现。它利用 CloudWeGo 实现了一个全流程的交通车道。这个笔记平台需要具备响应迅速和高效的特点，而 CloudWeGo 的高性能网络库 Netpoll 满足了这一需求。\nCloudWeGo 的整合将 Easy Note 应用提升至能与其他笔记平台有效竞争的水平，证明了简洁确实能带来力量。\nimport ( \u0026#34;github.com/cloudwego/kitex/server\u0026#34; ) type RPCService struct{} func (s *RPCService) Handle(ctx context.Context, req *Request) (*Response, error) { resp := \u0026amp;Response{Message: \u0026#34;Echo \u0026#34; + req.Message} return resp, nil } func main() { rpcHandler := \u0026amp;RPCService{} svr := server.NewServer(rpcHandler) listener, _ := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8888\u0026#34;) svr.Serve(listener) } 上述片段展示了 CloudWeGo 如何助力提升 Easy Note 应用的效率。\nBook Shop：轻松实现电子商务 在繁忙的电子商务领域，Book Shop 成为 CloudWeGo 无缝集成能力的明证。将 Elasticsearch 和 Redis 等中间件整合到 Kitex 项目中，构建起一个坚实且能与更复杂平台媲美的电子商务系统。\nCloudWeGo 与 Elasticsearch 和 Redis 等流行技术的有效整合能力，确保了企业在选择开源 RPC 框架时无需妥协。\nimport ( \u0026#34;github.com/cloudwego/kitex/server\u0026#34; ) type ItemService struct {} func (s *ItemService) AddItem(ctx context.Context, item *Item) error { // Add to Elasticsearch // Add to Redis // Return error if any return nil } func main() { itemHandler := \u0026amp;ItemService{} svr := server.NewServer(itemHandler) listener, _ := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8888\u0026#34;) svr.Serve(listener) } 上述代码片段展示了 Book Shop 电子商务系统如何与 CloudWeGo、Elasticsearch 和 Redis 协同运作的基本示例。\nFreeCar：驱动创新 FreeCar 项目是 CloudWeGo 如何革新分时租车系统运营的绝佳例证，为现有的打车应用提供了一个强有力的替代方案。\n这一实际应用展示了 CloudWeGo 强大功能如何优化运营，促进各行各业（不仅仅是科技领域）的效率与可扩展性。\nimport ( \u0026#34;github.com/cloudwego/kitex/server\u0026#34; ) type CarService struct {} func (s *CarService) BookRide(ctx context.Context, rideRequest *RideRequest) (*RideConfirmation, error) { // Business logic to handle ride booking // Return confirmation or error return nil, nil } func main() { rideHandler := \u0026amp;CarService{} svr := server.NewServer(rideHandler) listener, _ := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8888\u0026#34;) svr.Serve(listener) } 上述代码片段简要展示了 FreeCar 如何利用 CloudWeGo。\n是什么吸引我来到 CloudWeGo？ 当我深入探索替代 RPC 框架的领域，并研究 CloudWeGo 项目时，有几个因素尤为突出：\n性能：在微服务领域，性能可能意味着成功与失败之间的差距。CloudWeGo 在性能方面表现出色，其 QPS 和延迟得分让其他 RPC 框架望尘莫及。 可扩展性：作为开发者，你最欣赏 Kitex 的地方在于其承诺的可扩展性，使项目能够迅速适应不断增长的数据需求和复杂性。 鲁棒性：CloudWeGo 丰富的功能集，包括对多种消息协议、传输协议、负载均衡、断路器和限流的支持，为设计和维护微服务提供了全面的解决方案。 社区支持：CloudWeGo 由字节跳动支持，这让我确信能获得强大的社区支持。丰富的资源和讨论可解决常见问题，并支持持续学习。 实际应用：在多样化的项目中，CloudWeGo 展现出的多功能性和可扩展性，证实了我对其效能的信任。 拥抱微服务架构的未来 随着每个用例的实践，CloudWeGo 的潜力愈发清晰。开发者现在能够构建高性能、可扩展且稳健的应用程序，无论他们偏好使用 Golang 还是 Rust，都能真正掌握微服务的精髓。\n若您正考虑为微服务架构引入新工具，尤其是对 Rust 感兴趣，不妨尝试 CloudWeGo。微服务的未来正等着您。\n","permalink":"http://localhost:1313/posts/%E6%B7%B1%E5%85%A5%E6%8E%A2%E7%B4%A2%E5%88%A9%E7%94%A8cloudwego%E4%B8%B0%E5%AF%8Cgo%E8%AF%AD%E8%A8%80%E5%BE%AE%E6%9C%8D%E5%8A%A1/","summary":"介绍CloudWeGo如何构建微服务","title":"深入探索：利用CloudWeGo丰富Go语言微服务"},{"content":"前言 源于看到了这两篇博客基于 Rust 的高性能 RocketMQ Proxy、RocketMQ 5.0：无状态代理模式的探索与实践，兴趣使然，想探究下Proxy现有的设计实现，为自主实现各大MQ协议互转Proxy代理铺垫。也就是第一篇博客实现的Proxy，看起来在RocketMQ未来规划中是有的。关于Coding需要体会下才得道。\n下面开始。。。\n从0到“Hello World”，最快的方式优先从“QuickSstart”体验下。体验下总结就是这麽几个步骤：\n启动NameServer 选择``Broker+Proxy同进程，Broker、Proxy分离(不同进程)部署，不过内部的步骤也是先启动Broker，再Proxy` 测试Producer/Consumer 总所周知，源码不会唬人，所以接下来基于源码按照这个步骤展开。。。。\n这里用的IDE主要是 Idea。\n克隆项目 # 克隆代码 git clone https://github.com/apache/rocketmq.git 切换到 release-2.5.0\n构建Maven依赖\n然后IDE中maven install或者终端mvn clean install -Dmaven.test.skip=true\n最后主要关注项目中中这几个模块\n启动NameServer 复制“distribution”模块的绝对路径\nIDE-配置“NameServStartup”启动项\n找到“namasrv”模块的启动类“NameServStartup”\nmain方法启动，然后会提示需要设置“ROCKETMQ_HOME”\n打开启动配置框\n设置环境变量“ROCKETMQ_HOME”为“distribution”模块绝对路径，确定\n重新启动，看下面打印，启动成功\n选择 Broker、Proxy分离部署 选择分离部署，字面意思也是互不影响，主要是方便调试，因为我们的目标是Proxy。\n启动Broker 找到“broker”模块下的“BrokerStartup”启动类，main函数启动（会提示没有“ROCKETMQ_HOME”）\n打开IDE启动配置，设置启动参数和环境变量“ROCKETMQ_HOME”\n添加VM参数：-Xms512m -Xmx512m -Xmn256m\n-n 是你本机的nameserv，把“192.168.1.128”改成你自己的\n设置环境变量“ROCKETMQ_HOME”为之前复制的“distribution”的绝对路径\n重新启动，启动打印如下\n启动Proxy 找到“proxy”模块中启动类“ProxyStartup”，main函数启动，然后停止\n打开启动配置，设置启动参数和环境变量\n-n “192.168.1.128”修改为你的IP，表示代理的broker-server服务\n重新启动，打印如下\n测试 直连broker Producer\n找到“example”模块“quickstart”包下“Producer”类，main启动（会报错连接不上），停止\n打开启动配置，设置环境变量：NAMESRV_ADDR\n修改“192.168.1.128”为你的IP\n重新启动，推送消息打印\n异常如果是下面截图所示，暂时快速解决方法：重启 BrokerStartup\nConsumer\n找到“example”模块“quickstart”包下“Consumer”类，main启动（会报错连接不上），停止\n打开启动配置，设置环境变量：NAMESRV_ADDR\n重启启动，消费记录如下\n通过proxy测试 根据官方QuickStart中SDK测试消息收发指南进行测试。\n创建Java工程\n引入maven依赖，查看最新版本\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-client-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${rocketmq-client-java-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 通过mqadmin创建 Topic。\n这里指南中其实使用的Rocketmq源码中的tools模块下``MQAdminStartup`类，所以接下来我们回到源码工程中：\n启动MQAdminStartup类，看结果，是一个命令行工具\n打开启动配置，添加启动参数：updatetopic -n localhost:9876 -t TestTopic -c DefaultCluster\n执行成功如下打印\n出此之外你还可以安装：apache/rocketmq-dashboard，用来可视化查看mq的一些情况，建议使用docker安装，注意web端口8080映射为别的端口，默认和proxy默认端口冲突了\nProducer：回到刚刚的新工程中，创建“ProducerExample”类\nimport org.apache.rocketmq.client.apis.ClientConfiguration; import org.apache.rocketmq.client.apis.ClientConfigurationBuilder; import org.apache.rocketmq.client.apis.ClientException; import org.apache.rocketmq.client.apis.ClientServiceProvider; import org.apache.rocketmq.client.apis.message.Message; import org.apache.rocketmq.client.apis.producer.Producer; import org.apache.rocketmq.client.apis.producer.SendReceipt; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class ProducerExample { private static final Logger logger = LoggerFactory.getLogger(ProducerExample.class); public static void main(String[] args) throws ClientException { // 接入点地址，需要设置成Proxy的地址和端口列表，一般是xxx:8081;xxx:8081。 String endpoint = \u0026#34;192.168.1.128:8081\u0026#34;; // 消息发送的目标Topic名称，需要提前创建。 String topic = \u0026#34;TestTopic\u0026#34;; ClientServiceProvider provider = ClientServiceProvider.loadService(); ClientConfigurationBuilder builder = ClientConfiguration.newBuilder().setEndpoints(endpoint); ClientConfiguration configuration = builder.build(); // 初始化Producer时需要设置通信配置以及预绑定的Topic。 Producer producer = provider.newProducerBuilder() .setTopics(topic) .setClientConfiguration(configuration) .build(); // 普通消息发送。 Message message = provider.newMessageBuilder() .setTopic(topic) // 设置消息索引键，可根据关键字精确查找某条消息。 .setKeys(\u0026#34;messageKey\u0026#34;) // 设置消息Tag，用于消费端根据指定Tag过滤消息。 .setTag(\u0026#34;messageTag\u0026#34;) // 消息体。 .setBody(\u0026#34;messageBody\u0026#34;.getBytes()) .build(); try { // 发送消息，需要关注发送结果，并捕获失败等异常。 SendReceipt sendReceipt = producer.send(message); logger.info(\u0026#34;Send message successfully, messageId={}\u0026#34;, sendReceipt.getMessageId()); } catch (ClientException e) { logger.error(\u0026#34;Failed to send message\u0026#34;, e); } // producer.close(); } } Consumer：创建“PushConsumerExample”类\nimport java.io.IOException; import java.util.Collections; import org.apache.rocketmq.client.apis.ClientConfiguration; import org.apache.rocketmq.client.apis.ClientException; import org.apache.rocketmq.client.apis.ClientServiceProvider; import org.apache.rocketmq.client.apis.consumer.ConsumeResult; import org.apache.rocketmq.client.apis.consumer.FilterExpression; import org.apache.rocketmq.client.apis.consumer.FilterExpressionType; import org.apache.rocketmq.client.apis.consumer.PushConsumer; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class PushConsumerExample { private static final Logger logger = LoggerFactory.getLogger(PushConsumerExample.class); private PushConsumerExample() { } public static void main(String[] args) throws ClientException, IOException, InterruptedException { final ClientServiceProvider provider = ClientServiceProvider.loadService(); // 接入点地址，需要设置成Proxy的地址和端口列表，一般是xxx:8081;xxx:8081。 String endpoints = \u0026#34;192.168.1.128:8081\u0026#34;; ClientConfiguration clientConfiguration = ClientConfiguration.newBuilder() .setEndpoints(endpoints) .build(); // 订阅消息的过滤规则，表示订阅所有Tag的消息。 String tag = \u0026#34;*\u0026#34;; FilterExpression filterExpression = new FilterExpression(tag, FilterExpressionType.TAG); // 为消费者指定所属的消费者分组，Group需要提前创建。 String consumerGroup = \u0026#34;YourConsumerGroup\u0026#34;; // 指定需要订阅哪个目标Topic，Topic需要提前创建。 String topic = \u0026#34;TestTopic\u0026#34;; // 初始化PushConsumer，需要绑定消费者分组ConsumerGroup、通信参数以及订阅关系。 PushConsumer pushConsumer = provider.newPushConsumerBuilder() .setClientConfiguration(clientConfiguration) // 设置消费者分组。 .setConsumerGroup(consumerGroup) // 设置预绑定的订阅关系。 .setSubscriptionExpressions(Collections.singletonMap(topic, filterExpression)) // 设置消费监听器。 .setMessageListener(messageView -\u0026gt; { // 处理消息并返回消费结果。 logger.info(\u0026#34;Consume message successfully, messageId={}\u0026#34;, messageView.getMessageId()); return ConsumeResult.SUCCESS; }) .build(); Thread.sleep(Long.MAX_VALUE); // 如果不需要再使用 PushConsumer，可关闭该实例。 // pushConsumer.close(); } } 启动Producer，打印如下\n启动Consumer，打印如下\n好了，debug环境搭建好了，可以开始愉快的Debug。。。\n","permalink":"http://localhost:1313/posts/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BArocketmq-5.2%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83/","summary":"构建最小可调试环境","title":"如何构建RocketMQ-5.2源码调试环境"},{"content":" 前言\n这两天有个朋友公司有这麽一个情况，有个客户部署环境网络使用的是专线，完全内网，无法外网访问，确实安全，系统是Windows；离他们公司也很远，每次有问题都得开车7、8个小时才能到现场，酒店也不好找，来回一次开销不小；所以朋友就想能不能在有问题时，能远程解决问题。\n朋友立刻想到了USB快捷wifi网卡，里面插电话卡的那种，这卡的话费相比每次来回开销毛毛雨。\n眼看网卡到了，兴奋的插上，习惯性打开浏览器….baidu.com,嘿，百度一下。。。成了。。\n就在这时转头看了下系统大屏（实时的），问题出来了，看板数据没有了。\n出于回滚的思路，朋友马上把wifi网卡拔掉了，嘿。。看板数据恢复了。\n基于这两个现象描述，我简单判断为网络层的问题。\n查看全部路由\n接下来我让朋友把wifi卡插上，然后终端route print\n网络目标 网络掩码 网关 接口 跃点数 0.0.0.0 0.0.0.0 192.168.216.1 192.168.216.100 291 0.0.0.0 0.0.0.0 62.65.32.1 62.65.32.94 281 明显“0.0.0.0”两条路由冲突，然后数据到了机器后，机器不知道发给哪个，所以大屏就没有数据了\n查看网卡信息：ifconfig\n以太网适配器 xxx 2: 连接特定的 DNS 后缀 . . . . . . . : 本地链接 IPv6 地址. . . . . . . . : x::x:x:x:x IPv4 地址 . . . . . . . . . . . . : 62.65.32.94 子网掩码 . . . . . . . . . . . . : 255.255.255.128 默认网关. . . . . . . . . . . . . : 62.65.32.1 以太网适配器 以太网: 连接特定的 DNS 后缀 . . . . . . . : 本地链接 IPv6 地址. . . . . . . . : x::x:x:x:x IPv4 地址 . . . . . . . . . . . . : 192.168.216.100 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : 192.168.216.1 解决路由冲突：内网和外网使用不同的网卡\n接下来，我让朋友先把wifi的网卡改成静态IP（之前默认是DHCP）\n然后，删除这两条路由：route delete 0.0.0.0\n然后，添加0.0.0.0路由，加-p防止丢失\nroute -p add 0.0.0.0 mask 0.0.0.0 192.168.216.1 然后，添加62.65.0.0路由，同时也加-p\nroute -p add 62.65.0.0 mask 255.255.0.0 62.65.32.1 这时看数据看板就有数据\n但是还没完，还需要访问另外一个系统，ip是172.19.39.99,这个时候又访问不通了，再没有这个wifi网卡时是可以访问的，由此可以得到，之前访问Ip时，默认路由0.0.0.0是内网。此刻默认路由设置的是这个wifi的，所以无法访问到172.19.39.99。\n指定网段走指定网卡\n那么就在加一条172.19.39.0路由\nroute -p add 172.19.39.0 mask 255.255.255.0 62.65.32.1 此时，再使用浏览器，就可以访问了。\n这里是win的OS，其他的OS遇到此类问题同样可以使用此思路。\n扩展\nroute | Microsoft Learn Mac环境需要使用netstat -nr代替route print,具体可以查看Mac OS路由设置常命令 route(8) - Linux manual page (man7.org) ","permalink":"http://localhost:1313/posts/%E6%8C%87%E5%AE%9A%E7%BD%91%E6%AE%B5%E8%B7%AF%E7%94%B1%E6%8C%87%E5%AE%9A%E7%BD%91%E5%8D%A1/","summary":"双卡内外任我行：指定网段路由指定网卡","title":"指定网段路由指定网卡"},{"content":"“top”是一个强大的、轻量级的命令行工具，可以提供有关系统范围资源利用率的实时报告。它在各种 Linux 发行版中普遍可用。然而，我们发现它在 Docker 容器中执行时可能无法准确报告信息。这篇文章旨在引起您对这个问题的关注。\ndocker容器中的CPU压力测试 让我们进行一个简单的实验。我们将使用 Ubuntu 映像部署容器并有意增加 CPU 消耗。执行以下命令：\ndocker run -ti --rm --name tmp-limit --cpus=\u0026#34;1\u0026#34; -m=\u0026#34;1G\u0026#34; ubuntu bash -c \u0026#39;apt update; apt install -y stress; stress --cpu 4\u0026#39; 提供的命令执行以下操作：\n使用 Ubuntu 镜像启动容器 将 CPU 限制设置为 1 设置内存限制为1G 执行命令‘apt update; apt install -y 压力； stress –cpu 4’ 进行 CPU 压力测试 主机顶部报告的 CPU 利用率 现在，让我们在运行该 Docker 容器的主机上启动 top 工具。 top工具的输出如下：\n请注意图 1 中的橙色矩形。该指标显示为 25% CPU 利用率，并且它是正确的值。主机有 4 个核心，我们为容器分配了 1 个核心的限制。由于该单个核心已得到充分利用，报告的主机级别 CPU 利用率为 25%（即总核心的 1/4）。\n容器顶部报告的 CPU 利用率 现在，让我们在容器内执行 top 命令。以下是top命令报告的输出：\n请观察图 2 中的橙色矩形。CPU 利用率为 25%，反映了主机的值。然而，从容器的角度来看，这是不准确的，因为它已充分利用其分配的 100% CPU 限制。\n尽管如此，值得注意的是图 2 中列出的过程是准确的。该工具仅正确报告在此容器内运行的进程，并排除整个主机中的进程。\n如何找到容器中准确的CPU利用率？ 在这样的场景下，要获得容器内准确的CPU利用率，有以下几种解决方案：\nDocker 容器统计信息（docker stats）\ndocker stats 命令提供容器级别的基本资源利用率指标。以下是先前启动的容器的“docker stats”的输出：\n请注意图 3 中的橙色矩形。CPU 利用率显示为 100.64%。然而，挑战在于“docker stats”无法在容器内执行（除非将docker套接字传递到容器中，这种情况不常见并且会带来安全风险）。它必须从主机运行。\n容器顾问（cAdvisor）\n您可以利用本质上支持 Docker 容器的 cAdvisor（容器顾问）工具来提供容器级资源利用率指标。\nyCrash\n此外，您还可以选择使用 yCrash 工具，该工具不仅提供容器级指标，还分析应用程序级转储（例如垃圾收集日志、应用程序日志、线程、内存转储等）并提供全面的根原因分析报告。\n结论 虽然“top”是监控系统范围资源利用率的可靠工具，但它在 Docker 容器中的准确性可能会受到影响。这种差异可能会导致对容器性能的误解，尤其是在 CPU 利用率方面。正如我们的实验所示，“top”报告了容器内 25% 的 CPU 使用率，尽管已充分利用了分配的 CPU 限制。\n为了获得 Docker 容器内的精确指标，Docker Container Stats、cAdvisor 和 yCrash 等替代工具可以提供有关资源利用率的宝贵见解。通过利用这些工具，用户可以确保准确监控和优化容器化环境，最终提高性能和运营效率。\n原文：‘top’ reporting accurate metrics within containers?\n","permalink":"http://localhost:1313/posts/%E5%A6%82%E4%BD%95%E6%89%BE%E5%88%B0%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%87%86%E7%A1%AE%E7%9A%84cpu%E5%88%A9%E7%94%A8%E7%8E%87/","summary":"TOP 指令怎么准确定位容器的真实情况.","title":"如何找到容器中准确的CPU利用率？"},{"content":"性能监控工具 服务端的配置和性能 show profile # 案例 # all：显示所有性能信息 show profile all for query n # block io：显示块io操作的次数 show profile block io for query n # context switches：显示上下文切换次数，被动和主动 show profile context switches for query n # cpu：显示用户cpu时间、系统cpu时间 show profile cpu for query n # IPC：显示发送和接受的消息数量 show profile ipc for query n # page faults：显示页错误数量 show profile page faults for query n # source：显示源码中的函数名称与位置 show profile source for query n # swaps：显示swap的次数 show profile swaps for query n 运行时性能 performance_schema 简介 它是数据库中的库，使用的存储引擎是performance_schema，主要关注的是数据库运行过程中的性能相关的数据，与information_schema不同，关注的是数据库表的元数据 server内部在发生函数调用、操作系统的等待、SQL语句的执行阶段、单个SQL或者多个SQL的集合的事件来触发采集消耗、耗时、活动执行次数等信息，并且事件的采集可以方便的提供server中的相关存储引擎对磁盘文件、表I/O、表锁等资源同步多用相关信息 它的记录只会在server本地，不会记录到binlog，同时也不复制到其他的server，其实在mysql源代码实现过程中主要是通过检查点（埋点）的方式收集 可以通过select查询，同时也还可以修改相关收集配置，动态修改setup_*开头的几个配置表 表分类 -- 事件表：当前语句、历史语句、长语句历史、聚合后的摘要summary -- 其中，summary表还可以根据帐号(account),主机(host),程序(program), -- 线程(thread),用户(user)和全局(global)再进行细分) show tables like \u0026#39;%statement%\u0026#39;; -- 等待事件记录表，与语句事件类型的相关记录表类似： show tables like \u0026#39;%wait%\u0026#39;; -- 阶段事件记录表，记录语句执行的阶段事件的表 show tables like \u0026#39;%stage%\u0026#39;; -- 事务事件记录表，记录事务相关的事件的表 show tables like \u0026#39;%transaction%\u0026#39;; -- 监控文件系统层调用的表 show tables like \u0026#39;%file%\u0026#39;; -- 监视内存使用的表 show tables like \u0026#39;%memory%\u0026#39;; -- 动态对performance_schema进行配置的配置表 show tables like \u0026#39;%setup%\u0026#39;; 入门使用 首先需要查看是否开启此功能，需要显示的修改[my.cnf]配置文件\n-- 查看performance_schema的属性 mysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;performance_schema\u0026#39;; +--------------------+-------+ | Variable_name | Value | +--------------------+-------+ | performance_schema | ON | +--------------------+-------+ 1 row in set (0.01 sec) -- 在配置文件中修改performance_schema的属性值，on表示开启，off表示关闭 [mysqld] performance_schema=ON -- 切换数据库 use performance_schema; -- 查看当前数据库下的所有表,会看到有很多表存储着相关的信息 show tables; -- 可以通过show create table tablename来查看创建表的时候的表结构 mysql\u0026gt; show create table setup_consumers; +-----------------+--------------------------------- | Table | Create Table +-----------------+--------------------------------- | setup_consumers | CREATE TABLE `setup_consumers` ( `NAME` varchar(64) NOT NULL, `ENABLED` enum(\u0026#39;YES\u0026#39;,\u0026#39;NO\u0026#39;) NOT NULL ) ENGINE=PERFORMANCE_SCHEMA DEFAULT CHARSET=utf8 | +-----------------+--------------------------------- 1 row in set (0.00 sec) 两个概念 instruments：生产者，用于采集mysql中各种各样的操作产生的事件信息，对应配置表中的配置项我们可以称为监控采集配置项，前面动态表setup_*配置 consumers：消费者，对应的消费者表用于存储来自instruments采集的数据，对应配置表中的配置项我们可以称为消费存储配置项 常用配置项 启动配置 # 是否在mysql server启动时就开启events_statements_current表的记录功能(该表记录当前的语句事件信息)， # 启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新setup_consumers配置 # 表中的events_statements_current配置项，默认值为TRUE performance_schema_consumer_events_statements_current=TRUE # 与performance_schema_consumer_events_statements_current选项类似， # 但该选项是用于配置是否记录语句事件短历史信息，默认为TRUE performance_schema_consumer_events_statements_history=TRUE # 与performance_schema_consumer_events_statements_current选项类似， # 但该选项是用于配置是否记录语句事件长历史信息，默认为FALSE performance_schema_consumer_events_stages_history_long=FALSE # 除了statement(语句)事件之外，还支持：wait(等待)事件、state(阶段)事件、transaction(事务)事件， # 他们与statement事件一样都有三个启动项分别进行配置，但这些等待事件默认未启用， # 如果需要在MySQL Server启动时一同启动，则通常需要写进my.cnf配置文件中 # 是否在MySQL Server启动时就开启全局表（如： # mutex_instances、rwlock_instances、cond_instances、file_instances、 # users、hostsaccounts、socket_summary_by_event_name、file_summary_by_instance # 等大部分的全局对象计数统计和事件汇总统计信息表 ）的记录功能， # 启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新全局配置项,默认值为TRUE performance_schema_consumer_global_instrumentation=TRUE # 是否在MySQL Server启动时就开启events_statements_summary_by_digest 表的记录功能， # 启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新digest配置项,默认值为TRUE performance_schema_consumer_statements_digest=TRUE # 是否在MySQL Server启动时就开启 performance_schema_consumer_thread_instrumentation=TRUE # events_xxx_summary_by_yyy_by_event_name表的记录功能， # 启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新线程配置项,默认值为TRUE performance_schema_instrument[=name] # 是否在MySQL Server启动时就启用某些采集器，由于instruments配置项多达数千个， # 所以该配置项支持key-value模式，还支持%号进行通配等，如下: # [=name]可以指定为具体的Instruments名称（但是这样如果有多个需要指定的时候，就需要使用该选项多次）， # 也可以使用通配符，可以指定instruments相同的前缀+通配符， # 也可以使用%代表所有的instruments指定开启单个instruments performance-schema-instrument=\u0026#39;instrument_name=value\u0026#39; # 使用通配符指定开启多个instruments performance-schema-instrument=\u0026#39;wait/synch/cond/%=COUNTED\u0026#39; # 开关所有的instruments performance-schema-instrument=\u0026#39;%=ON\u0026#39; performance-schema-instrument=\u0026#39;%=OFF\u0026#39; # 注意，这些启动选项要生效的前提是，需要设置performance_schema=ON。 # 另外，这些启动选项虽然无法使用show variables语句查看， # 但我们可以通过setup_instruments和setup_consumers表查询这些选项指定的值。 系统变量 # 查询是否开启运行时事件记录功能 show variables like \u0026#39;%performance_schema%\u0026#39;; # 重要的属性解释 # 控制performance_schema功能的开关，要使用MySQL的performance_schema，需要在mysqld启动时启用，以启用事件收集功能，该参数 # 在5.7.x之前支持performance_schema的版本中默认关闭，5.7.x版本开始默认开启 # 注意：如果mysqld在初始化performance_schema时发现无法分配任何相关的内部缓冲区，则performance_schema将自动禁用，并将performance_schema设置为OFF performance_schema=ON # 控制events_statements_summary_by_digest表中的最大行数。如果产生的语句摘要信息超过此最大值， # 便无法继续存入该表，此时performance_schema会增加状态变量 performance_schema_digests_size=10000 # 控制events_statements_history_long表中的最大行数， # 该参数控制所有会话在events_statements_history_long表中能够存放的 # 总事件记录数，超过这个限制之后，最早的记录将被覆盖全局变量， # 只读变量，整型值，5.6.3版本引入 * 5.6.x版本中，5.6.5及其之前的版 # 本默认为10000，5.6.6及其之后的版本默认值为-1，通常情况下， # 自动计算的值都是10000 * 5.7.x版本中，默认值为-1，通常情况下，自动 # 计算的值都是10000 performance_schema_events_statements_history_long_size=10000 # 控制events_statements_history表中单个线程（会话）的最大行数，该参数控制单个会话在 # events_statements_history表中能够存放的事件记录数，超过这个限制之后，单个会话最早的记录将被覆盖 # 全局变量，只读变量，整型值，5.6.3版本引入 * 5.6.x版本中，5.6.5及其之前的版本默认为10，5.6.6及其之后的版本默认值为-1， # 通常情况下，自动计算的值都是10 * 5.7.x版本中，默认值为-1，通常情况下，自动计算的值都是10 # 除了statement(语句)事件之外，wait(等待)事件、state(阶段)事件、transaction(事务)事件， # 他们与statement事件一样都有三个参数分别进行存储限制配置，有兴趣的同学自行研究，这里不再赘述 performance_schema_events_statements_history_size=10 # 用于控制标准化形式的SQL语句文本在存入performance_schema时的限制长度， # 该变量与max_digest_length变量相关(max_digest_length变量含义请自行查阅相关资料)全局变量， # 只读变量，默认值1024字节，整型值，取值范围0~1048576 performance_schema_max_digest_length=1024 # 控制存入events_statements_current，events_statements_history和events_statements_history_long语句事件表中的 # SQL_TEXT列的最大SQL长度字节数。 超出系统变量performance_schema_max_sql_text_length的部分将被丢弃，不会记录，一般情况 # 下不需要调整该参数，除非被截断的部分与其他SQL比起来有很大差异 # 全局变量，只读变量，整型值，默认值为1024字节，取值范围为0~1048576，5.7.6版本引入 # 降低系统变量performance_schema_max_sql_text_length值可以减少内存使用，但如果汇总的SQL中，被截断部分有较大差异，会导致没 # 有办法再对这些有较大差异的SQL进行区分。 增加该系统变量值会增加内存使用，但对于汇总SQL来讲可以更精准地区分不同的部分。 performance_schema_max_sql_text_length=1024 setup_*配置表说明 /* performance_timers表中记录了server中有哪些可用的事件计时器 字段解释： timer_name:表示可用计时器名称，CYCLE是基于CPU周期计数器的定时器 timer_frequency:表示每秒钟对应的计时器单位的数量,CYCLE计时器的换算值与CPU的频率相关、 timer_resolution:计时器精度值，表示在每个计时器被调用时额外增加的值 timer_overhead:表示在使用定时器获取事件时开销的最小周期值 */ select * from performance_timers; /* setup_timers表中记录当前使用的事件计时器信息 字段解释： name:计时器类型，对应某个事件类别 timer_name:计时器类型名称 */ select * from setup_timers; /* setup_consumers表中列出了consumers可配置列表项 字段解释： NAME：consumers配置名称 ENABLED：consumers是否启用，有效值为YES或NO，此列可以使用UPDATE语句修改。 */ select * from setup_consumers; /* setup_instruments 表列出了instruments 列表配置项，即代表了哪些事件支持被收集： 字段解释： NAME：instruments名称，instruments名称可能具有多个部分并形成层次结构 ENABLED：instrumetns是否启用，有效值为YES或NO，此列可以使用UPDATE语句修改。如果设置为NO，则这个instruments不会被执行， 不会产生任何的事件信息 TIMED：instruments是否收集时间信息，有效值为YES或NO，此列可以使用UPDATE语句修改，如果设置为NO，则这个instruments不会收 集时间信息 */ SELECT * FROM setup_instruments; /* setup_actors表的初始内容是匹配任何用户和主机，因此对于所有前台线程，默认情况下启用监视和历史事件收集功能 字段解释： HOST：与grant语句类似的主机名，一个具体的字符串名字，或使用“％”表示“任何主机” USER：一个具体的字符串名称，或使用“％”表示“任何用户” ROLE：当前未使用，MySQL 8.0中才启用角色功能 ENABLED：是否启用与HOST，USER，ROLE匹配的前台线程的监控功能，有效值为：YES或NO HISTORY：是否启用与HOST， USER，ROLE匹配的前台线程的历史事件记录功能，有效值为：YES或NO */ SELECT * FROM setup_actors; /* setup_objects表控制performance_schema是否监视特定对象。默认情况下，此表的最大行数为100行。 字段解释： OBJECT_TYPE：instruments类型，有效值为：“EVENT”（事件调度器事件）、“FUNCTION”（存储函数）、“PROCEDURE”（存储过程）、 “TABLE”（基表）、“TRIGGER”（触发器），TABLE对象类型的配置会影响表I/O事件（wait/io/table/sql/handler instrument）和 表锁事件（wait/lock/table/sql/handler instrument）的收集 OBJECT_SCHEMA：某个监视类型对象涵盖的数据库名称，一个字符串名称，或“％”(表示“任何数据库”) OBJECT_NAME：某个监视类型对象涵盖的表名，一个字符串名称，或“％”(表示“任何数据库内的对象”) ENABLED：是否开启对某个类型对象的监视功能，有效值为：YES或NO。此列可以修改 TIMED：是否开启对某个类型对象的时间收集功能，有效值为：YES或NO，此列可以修改 */ SELECT * FROM setup_objects; /* threads表对于每个server线程生成一行包含线程相关的信息， 字段解释： THREAD_ID：线程的唯一标识符（ID） NAME：与server中的线程检测代码相关联的名称(注意，这里不是instruments名称) TYPE：线程类型，有效值为：FOREGROUND、BACKGROUND。分别表示前台线程和后台线程 PROCESSLIST_ID：对应INFORMATION_SCHEMA.PROCESSLIST表中的ID列。 PROCESSLIST_USER：与前台线程相关联的用户名，对于后台线程为NULL。 PROCESSLIST_HOST：与前台线程关联的客户端的主机名，对于后台线程为NULL。 PROCESSLIST_DB：线程的默认数据库，如果没有，则为NULL。 PROCESSLIST_COMMAND：对于前台线程，该值代表着当前客户端正在执行的command类型，如果是sleep则表示当前会话处于空闲状态 PROCESSLIST_TIME：当前线程已处于当前线程状态的持续时间（秒） PROCESSLIST_STATE：表示线程正在做什么事情。 PROCESSLIST_INFO：线程正在执行的语句，如果没有执行任何语句，则为NULL。 PARENT_THREAD_ID：如果这个线程是一个子线程（由另一个线程生成），那么该字段显示其父线程ID ROLE：暂未使用 INSTRUMENTED：线程执行的事件是否被检测。有效值：YES、NO HISTORY：是否记录线程的历史事件。有效值：YES、NO * THREAD_OS_ID：由操作系统层定义的线程或任务标识符（ID）： */ select * from threads 实践案例 了解相关的参数配置后，可以对表进行一些实际分析，\n-- 1、哪类的SQL执行最多？ SELECT DIGEST_TEXT,COUNT_STAR,FIRST_SEEN,LAST_SEEN FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC -- 2、哪类SQL的平均响应时间最多？ SELECT DIGEST_TEXT,AVG_TIMER_WAIT FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC -- 3、哪类SQL排序记录数最多？ SELECT DIGEST_TEXT,SUM_SORT_ROWS FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC -- 4、哪类SQL扫描记录数最多？ SELECT DIGEST_TEXT,SUM_ROWS_EXAMINED FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC -- 5、哪类SQL使用临时表最多？ SELECT DIGEST_TEXT,SUM_CREATED_TMP_TABLES,SUM_CREATED_TMP_DISK_TABLES FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC -- 6、哪类SQL返回结果集最多？ SELECT DIGEST_TEXT,SUM_ROWS_SENT FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC -- 7、哪个表物理IO最多？ SELECT file_name,event_name,SUM_NUMBER_OF_BYTES_READ,SUM_NUMBER_OF_BYTES_WRITE FROM file_summary_by_instance ORDER BY SUM_NUMBER_OF_BYTES_READ + SUM_NUMBER_OF_BYTES_WRITE DESC -- 8、哪个表逻辑IO最多？ SELECT object_name,COUNT_READ,COUNT_WRITE,COUNT_FETCH,SUM_TIMER_WAIT FROM table_io_waits_summary_by_table ORDER BY sum_timer_wait DESC -- 9、哪个索引访问最多？ SELECT OBJECT_NAME,INDEX_NAME,COUNT_FETCH,COUNT_INSERT,COUNT_UPDATE,COUNT_DELETE FROM table_io_waits_summary_by_index_usage ORDER BY SUM_TIMER_WAIT DESC -- 10、哪个索引从来没有用过？ SELECT OBJECT_SCHEMA,OBJECT_NAME,INDEX_NAME FROM table_io_waits_summary_by_index_usage WHERE INDEX_NAME IS NOT NULL AND COUNT_STAR = 0 AND OBJECT_SCHEMA \u0026lt;\u0026gt; \u0026#39;mysql\u0026#39; ORDER BY OBJECT_SCHEMA,OBJECT_NAME; -- 11、哪个等待事件消耗时间最多？ SELECT EVENT_NAME,COUNT_STAR,SUM_TIMER_WAIT,AVG_TIMER_WAIT FROM events_waits_summary_global_by_event_name WHERE event_name != \u0026#39;idle\u0026#39; ORDER BY SUM_TIMER_WAIT DESC -- 12-1、剖析某条SQL的执行情况，包括statement信息，stege信息，wait信息 SELECT EVENT_ID,sql_text FROM events_statements_history WHERE sql_text LIKE \u0026#39;%count(*)%\u0026#39;; -- 12-2、查看每个阶段的时间消耗 SELECT event_id,EVENT_NAME,SOURCE,TIMER_END - TIMER_START FROM events_stages_history_long WHERE NESTING_EVENT_ID = 1553; -- 12-3、查看每个阶段的锁等待情况 SELECT event_id,event_name,source,timer_wait,object_name,index_name,operation,nesting_event_id FROM events_waits_history_longWHERE nesting_event_id = 1553; 参考官方performance_schema教程\nshow processlist 当前由服务器内执行的线程集执行的操作情况，更多可以参考官网：Sources of Process Information\nSechema与数据类型优化 数据类型优化 三原则：占用越小越好，足够简单，避免为null\n实际操作建议\n整型：TINYINT，SMALLEST，MEDIUMINT，INT，BIGINT分别使用8，16，24，32，64位存储空间\n字符和字符串：char（255字）、vachar（65535字）、text类（TINYTEXT:2^8^-1、TEXT:2^16^ -1、MEDIUMTEXT:2^24^-1、LONGTEXT:4G或2^32^-1）单位字节\nBLOB和TEXT类型，分别是二进制和字符串格式来存储\ndatatime和timestamp\ndatatime（8字节） 与时区无关，数据库底层对datetime无效 可以精确到毫秒 可保存的范围大 字符串存储会导致确实时间的精度 date（3字节） 占用的字节数比字符串、datatime、int少 可以通过date类型进行日期计算 保存范围是1000-01-01到9999-12-31 timestamp（4字节） 时间范围是linux元年1970-01-01开始到2038-01-19 精确到秒 采用整型存储 依赖数据库的时区 自动更新timestamp的列值 尝试使用枚举代替字符串，mysql存储枚举类型非常的紧凑，有利于提升IO读取\n存储特殊类型通过可以通过函数转换如IP存储\n# 序列化 mysql\u0026gt; select inet_aton(\u0026#39;1.1.1.1\u0026#39;); +----------------------+ | inet_aton(\u0026#39;1.1.1.1\u0026#39;) | +----------------------+ | 16843009 | +----------------------+ 1 row in set (0.00 sec) # 反序列化 mysql\u0026gt; select inet_ntoa(16843009); +---------------------+ | inet_ntoa(16843009) | +---------------------+ | 1.1.1.1 | +---------------------+ 1 row in set (0.00 sec) 合理的范式和反范式 合理的范式 优点：更新更快，基本不会出现重复的数据，在内存中操作比较快 缺点：需要不断的关联，增加IO消耗 反范式 优点：所有的信息都在一张表中，可以避免关联，减少IO消耗 缺点：冗余较多，删除操作时会删除不必要信息 实践 项目前：先范式设计后分析业务反范式冗余存储，更新优先级根据业务来看（及时和延迟） 项目中：分析业务代码逻辑，是否需要优化数据表增加冗余字段减少IO的开销 主键选择 代理主键\n与业务无关，无意义的数字序列，如ID 自然主键\n和业务相关，事物属性唯一标识，如身份证 如何选择\n代理主键更好，不与业务耦合，更加容易维护，统一的策略，也减少源代码数量 字符集选择 mysql精确到字段取优化，合适的字符集，一定程度上也会减少IO\nlatin*：纯拉丁内容适合 utf-8*：多语言内容 存储引擎选择 适当的拆分 比如有字段类型为TEXT之类大型字段，可以尝试拆到单独的表，当查询不需要此字段的查询是，可以大大减少IO的处理时间 执行计划EXPLAIN 格式：explain + SQL EXPLAIN字段解析 mysql\u0026gt; explain select inet_aton(\u0026#39;1.1.1.1\u0026#39;)\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: NULL partitions: NULL type: NULL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: NULL filtered: NULL Extra: No tables used 1 row in set, 1 warning (0.00 sec) id有几种情况 id相同，顺序执行 id不同，递增，id号越大，越先执行 id相同和id不同同时存在，即第一种和第二种结合 null，代表是中间结果集（在8.x有些情况被优化了，5.x中还是存在的，比如 UNION RESULT） select_type -- sample:简单的查询，不包含子查询和union explain select * from emp; -- primary:查询中若包含任何复杂的子查询，最外层查询则被标记为Primary explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ; -- union:若第二个select出现在union之后，则被标记为union explain select * from emp where deptno = 10 union select * from emp where sal \u0026gt;2000; -- dependent union:跟union类似，此处的depentent表示union或union all联合而成的结果会受外部表影响 explain select * from emp e where e.empno in ( select empno from emp where deptno = 10 union select empno from emp where sal \u0026gt;2000) -- union result:从union表获取结果的select explain select * from emp where deptno = 10 union select * from emp where sal \u0026gt;2000; -- subquery:在select或者where列表中包含子查询 explain select * from emp where sal \u0026gt; (select avg(sal) from emp) ; -- dependent subquery:subquery的子查询要受到外部表查询的影响 explain select * from emp e where e.deptno in (select distinct deptno from dept); -- DERIVED: from子句中出现的子查询，也叫做派生类， explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ; -- UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被缓存 explain select * from emp where empno = (select empno from emp where deptno=@@sort_buffer_size); -- uncacheable union:表示union的查询结果不能被缓存：sql语句未验证 table 如果是具体的表名，则表明从实际的物理表中获取数据，当然也可以是表的别名 表名是derivedN的形式，表示使用了id为N的查询产生的衍生表 当有union result的时候，表名是union n1,n2等的形式，n1,n2表示参与union的id type system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; fulltext \u0026gt; ref_or_null \u0026gt; index_merge \u0026gt; unique_subquery \u0026gt; index_subquery \u0026gt; range \u0026gt; index \u0026gt; ALL -- all:全表扫描，一般情况下出现这样的sql语句而且数据量比较大的话那么就需要进行优化。 explain select * from emp; -- index：全索引扫描这个比all的效率要好，主要有两种情况，一种是当前的查询时覆盖索引， -- 即我们需要的数据在索引中就可以索取，或者是使用了索引进行排序，这样就避免数据的重排序 explain select empno from emp; -- range：表示利用索引查询的时候限制了范围，在指定范围内进行查询， -- 这样避免了index的全索引扫描，适用的操作符： =, \u0026lt;\u0026gt;, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=, IS NULL, BETWEEN, LIKE, or IN() explain select * from emp where empno between 7000 and 7500; -- index_subquery：利用索引来关联子查询，不再扫描全表 explain select * from emp where emp.job in (select job from t_job); -- unique_subquery:该连接类型类似与index_subquery,使用的是唯一索引 explain select * from emp e where e.deptno in (select distinct deptno from dept); -- index_merge：在查询过程中需要多个索引组合使用，没有模拟出来 -- ref_or_null：对于某个字段即需要关联条件，也需要null值的情况下，查询优化器会选择这种访问方式 explain select * from emp e where e.mgr is null or e.mgr=7369; -- fulltext：全文索引 -- ref：使用了非唯一性索引进行数据的查找 create index idx_3 on emp(deptno); explain select * from emp e,dept d where e.deptno =d.deptno; -- eq_ref：使用唯一性索引进行数据查找 explain select * from emp,emp2 where emp.empno = emp2.empno; -- const：这个表至多有一个匹配行， explain select * from emp where empno = 7369; -- system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现 possible_keys 这张table可能用的索引，不一定使用了\nkey 实际用到的索引，如果为null，则没有用索引，如果使用了覆盖索引，则会与select重叠\nkey_len 表示使用索引的字节长度，不损失精度情况，越短越好\nref 显示哪一列被使用了索引，是一个常数\nrows 根据表的统计信息及索引情况，大致的计算需要读取的行数\nextra -- using filesort:说明mysql无法利用索引进行排序，只能利用排序算法进行排序，会消耗额外的位置 explain select * from emp order by sal; -- using temporary:建立临时表来保存中间结果，查询完成之后把临时表删除 explain select ename,count(*) from emp where deptno = 10 group by ename; -- using index:这个表示当前的查询时覆盖索引的，直接从索引中读取数据， -- 而不用访问数据表。如果同时出现using where 表名索引被用来执行索引键值的查找， -- 如果没有，表面索引被用来读取数据，而不是真的查找 explain select deptno,count(*) from emp group by deptno limit 10; -- using where:使用where进行条件过滤 explain select * from t_user where id = 1; -- using join buffer:使用连接缓存，情况没有模拟出来 -- impossible where：where语句的结果总是false explain select * from emp where empno = 7469; 如何应用 type判断是否有使用索引，尽可能的到达range\u0026lt;type\u0026lt;ref ref判断是否用到索引 extra判断是否覆盖索引、排序是否用到索引 索引优化 索引基础 比如一本书的目录，可以让你快速的找到你感兴趣的内容\n优点 减少服务器扫描数据量 帮助服务器避免排序和临时表 将随机IO变成顺序IO 用处 快速的找到WHERE字句的行 优化器会找到最优索引 如果表具有多列索引，优化器会使用索引的任何最左前缀来找到行 当有表连接时，，从其他表检索行数据 找到特定的索引列min和max值 如果索引和分组时在可用的索引最左前缀上完成的，则对进行排序和分组 某些情况下，可以查询检索值，无需检索行，如覆盖索引的情况 分类 主键索引：PRIMARY KEY 唯一索引：UNIQUE 普通索引：NORMAL 全文索引：FULLTEXT 组合索引：KEY name(字段1,字段2,字段3) 一些名词 回表：比如我们需要查用户信息，通过name去查（name字段列是普通索引），普通索引中的data存储的是主键索ID,主键索引data存放的是数据行，执行器会通过普通索引定位到data后，再拿着ID去主键索引去查用户信息数据行(最后去主键索引查数据行的行为叫回表)，遍历2次B+树 覆盖索引：还是刚刚的例子，如果查询的不是用户信息，而是用户ID（主键ID），去掉上面例子中去主键索引的过程，就是覆盖索引，因为普通索引data就是用户ID，遍历1次B+树 最左匹配：B+树索引是有序的，从左往右递增，而组合索引就是从表的字段的左边字段开始匹配，遇到范围停止匹配 索引下推：将where后面的条件需要在server层过滤的变为在server层之前过滤完成，交给server层的就是结果集 索引常用的数据结构 哈希表+链表 B+树 发展历程 =\u0026gt;哈希表，查询时间复杂度（O(N)），为了降低时间复杂度人们想到了（logn）-\u0026gt; 二叉树 =\u0026gt;二叉树（分支倾斜严重） =\u0026gt;平衡二叉树（平衡分支耗时） =\u0026gt;红黑树（减少平衡距离，降低插入速度） \u0026mdash;分割线\u0026mdash;无论怎么优化二叉树，随着时间的推移，树的深度总会越来越深\u0026mdash;分割线\u0026mdash; =\u0026gt;B树： 每个节点（主键（主键+data）+指针（主键子节点范围））16K 这样的缺点，节点容量固定条件下，data越大，能存放的指针变小，从而导致索引容纳的数少 =\u0026gt;B+树 让最终的子节点去存放data，子节点的父节点都是指针 最底层data之间还通过链表相互连接，方便遍历 索引匹配的方式 name，age组合索引\n全值匹配：name=‘张三’ 匹配最左前缀：name=‘张三’ AND age=10 匹配列前缀：name like ‘张%’ 匹配范围值：age\u0026gt;10 精确匹配某一列+范围匹配：name=‘’ AND age \u0026gt; 10 只访问索引列：select name,age from user where name=‘张三’ AND age=10(覆盖索引) 哈希索引 结构：哈希表 + 链表 优点 结构非常的紧凑，然后查询很快 缺点 哈希索引结构只包含行指针和哈希值，不存储值 哈希不是顺序存储，无法排序 不支持分列匹配查找 只支持等值 =，or查找，不支持范围查找 冲突严重时，链表特别长耗时，维护耗时 案例 比如需要存放一个很长的URL，需求需要通过URL查询 我们可以通过一些哈希函数，如CRC32 这样可以减小体积 组合索引 多列共同组成索引树，where最左使用 聚族索引和非聚族索引 聚族索引：索引中data=元数据 INNODB中的主键索引存放的就是元数据 非聚族索引：索引中data!=元数据，而是元数据的地址 如MyISAM存储引擎的B+树，data存放的是元数据的文件地址 覆盖索引 一个索引data中有查询字段的值 实现方式和存储引擎有关，Momery存储引擎不支持 优势 减少IO，B+索引本就有顺序，在IO密集型范围内，读取一次数据IO减少很多 聚族索引支持更好，非聚族索引只做地址缓存严重影响性能 细节优化 单表6个以内索引 一个索引5个字段内 根据实际业务优化 少用表达式，计算放到业务层 优先主键索引，不会触发回表 使用前缀索引 使用索引排序 union all、in、or都能使用索引，in最好 范围，\u0026lt;,\u0026gt;，但是后面的字段就无法用索引了 索引监控 show status like \u0026lsquo;Handler_read%\u0026rsquo;; 参数解析 Handler_read_first：读取索引第一个条目的次数 Handler_read_key：通过index获取数据的次数 Handler_read_last：读取索引最后一个条目的次数 Handler_read_next：通过索引读取下一条数据的次数 Handler_read_prev：通过索引读取上一条数据的次数 Handler_read_rnd：从固定位置读取数据的次数 Handler_read_rnd_next：从数据节点读取下一条数据的次数 案例 预备数据 SET FOREIGN_KEY_CHECKS=0; DROP TABLE IF EXISTS `itdragon_order_list`; CREATE TABLE `itdragon_order_list` ( `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键id，默认自增长\u0026#39;, `transaction_id` varchar(150) DEFAULT NULL COMMENT \u0026#39;交易号\u0026#39;, `gross` double DEFAULT NULL COMMENT \u0026#39;毛收入(RMB)\u0026#39;, `net` double DEFAULT NULL COMMENT \u0026#39;净收入(RMB)\u0026#39;, `stock_id` int(11) DEFAULT NULL COMMENT \u0026#39;发货仓库\u0026#39;, `order_status` int(11) DEFAULT NULL COMMENT \u0026#39;订单状态\u0026#39;, `descript` varchar(255) DEFAULT NULL COMMENT \u0026#39;客服备注\u0026#39;, `finance_descript` varchar(255) DEFAULT NULL COMMENT \u0026#39;财务备注\u0026#39;, `create_type` varchar(100) DEFAULT NULL COMMENT \u0026#39;创建类型\u0026#39;, `order_level` int(11) DEFAULT NULL COMMENT \u0026#39;订单级别\u0026#39;, `input_user` varchar(20) DEFAULT NULL COMMENT \u0026#39;录入人\u0026#39;, `input_date` varchar(20) DEFAULT NULL COMMENT \u0026#39;录入时间\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=10003 DEFAULT CHARSET=utf8; INSERT INTO itdragon_order_list VALUES (\u0026#39;10000\u0026#39;, \u0026#39;81X97310V32236260E\u0026#39;, \u0026#39;6.6\u0026#39;, \u0026#39;6.13\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;ok\u0026#39;, \u0026#39;ok\u0026#39;, \u0026#39;auto\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;itdragon\u0026#39;, \u0026#39;2017-08-28 17:01:49\u0026#39;); INSERT INTO itdragon_order_list VALUES (\u0026#39;10001\u0026#39;, \u0026#39;61525478BB371361Q\u0026#39;, \u0026#39;18.88\u0026#39;, \u0026#39;18.79\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;ok\u0026#39;, \u0026#39;ok\u0026#39;, \u0026#39;auto\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;itdragon\u0026#39;, \u0026#39;2017-08-18 17:01:50\u0026#39;); INSERT INTO itdragon_order_list VALUES (\u0026#39;10002\u0026#39;, \u0026#39;5RT64180WE555861V\u0026#39;, \u0026#39;20.18\u0026#39;, \u0026#39;20.17\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;ok\u0026#39;, \u0026#39;ok\u0026#39;, \u0026#39;auto\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;itdragon\u0026#39;, \u0026#39;2017-09-08 17:01:49\u0026#39;); 案例一 select * from itdragon_order_list where transaction_id = \u0026#34;81X97310V32236260E\u0026#34;; -- 通过查看执行计划发现type=all,需要进行全表扫描 explain select * from itdragon_order_list where transaction_id = \u0026#34;81X97310V32236260E\u0026#34;; -- 优化一、为transaction_id创建唯一索引 create unique index idx_order_transaID on itdragon_order_list (transaction_id); -- 当创建索引之后，唯一索引对应的type是const，通过索引一次就可以找到结果，普通索引对应的type是ref，表示非唯一性索引赛秒，找到值还要进行扫描，直到将索引文件扫描完为止，显而易见，const的性能要高于ref explain select * from itdragon_order_list where transaction_id = \u0026#34;81X97310V32236260E\u0026#34;; -- 优化二、使用覆盖索引，查询的结果变成 transaction_id,当extra出现using index,表示使用了覆盖索引 explain select transaction_id from itdragon_order_list where transaction_id = \u0026#34;81X97310V32236260E\u0026#34;; 案例二 -- 创建复合索引 create index idx_order_levelDate on itdragon_order_list (order_level,input_date); -- 创建索引之后发现跟没有创建索引一样，都是全表扫描，都是文件排序 explain select * from itdragon_order_list order by order_level,input_date; -- 可以使用force index强制指定索引 explain select * from itdragon_order_list force index(idx_order_levelDate) order by order_level,input_date; -- 其实给订单排序意义不大，给订单级别添加索引意义也不大 -- 因此可以先确定order_level的值，然后再给input_date排序 explain select * from itdragon_order_list where order_level=3 order by input_date; 查询SQL优化 查询慢的原因 网络、CPU、IO、上下文切换、系统调用、生成统计信息、锁等待时间\n数据访问优化 在无法避免的大量数据过程中，检查应用程序和mysql服务器是否在检索大量无需的字段 是请求了无关的字段，如下 查询不需要的字段 多表返回了全部列 总是取出全部列 重复查询相同的数据 执行过程优化 =\u0026gt;查询缓存（8.x已经完全删除） mysql连接器后尝试去命中缓存，命中返回\n=\u0026gt;解析SQL和预处理：分析器 通过关键字将SQL语句进行解析并生成一颗解析树 mysql解析器将使用mysql语法规则验证和解析查询 =\u0026gt;优化SQL执行计划：优化器 初略统计 表和索引的页面数、索引个数 索引和数据行长度 索引分布情况 大多情况下会选择错误的执行计划，原因如下 统计信息不准确：innodb的MVCC会有过个版本 执行计划成本估算不等于实际执行成本：mysql不知道那些数据实际在内存中和磁盘中 优化器认为的最优的和现实不一样：基于成本模型，但不是我们认为的最优 不考虑并发执行的查询 不考虑不受其控制操作的成本：比如自定义函数 优化器策略 动态优化：与查询的上下文、取值、索引的函数有关，优化N次 静态优化：直接优化解析树，只优化一次 优化器类型 重新定义关联顺序\n外连接转化为内连接\n使用等价代换规则，可以使用一些等价简化的表达式\ncount（）、Min（）、Max（）：索引列不为NULL可以优化这类\n预估并转化常数表达式，检查到可以是一个常数，即转化为常数\n覆盖索引扫描，符合‘覆盖索引’条件即用\n子查询优化：在某些情况下，子查询会变为缓存\n等值传播\n如果两个列的值通过等式关联，那么mysql能够把其中一个列的where条件传递到另一个上： explain select film.film_id from film inner join film_actor using(film_id) where film.film_id \u0026gt; 500; 这里使用film_id字段进行等值关联，film_id这个列不仅适用于film表而且适用于film_actor表 explain select film.film_id from film inner join film_actor using(film_id) where film.film_id \u0026gt; 500 and film_actor.film_id \u0026gt; 500; 关联查询优化 简单关联\n有索引关联\n无索引关联\n（1）Join Buffer会缓存所有参与查询的列而不是只有Join的列。 （2）可以通过调整join_buffer_size缓存大小 （3）join_buffer_size的默认值是256K，join_buffer_size的最大值在MySQL 5.1.22版本前是4G-1，而之后的版本才能在64位操作系统下申请大于4G的Join Buffer空间。 （4）使用Block Nested-Loop Join算法需要开启优化器管理配置的optimizer_switch的设置block_nested_loop为on，默认为开启。\n查询optimizer_switch设置情况：show variables like \u0026lsquo;%optimizer_switch%\u0026rsquo;;\n-- 案例 -- 查看不同的顺序执行方式对查询性能的影响： explain select film.film_id, film.title, film.release_year, actor.actor_id, actor.first_name, actor.last_name from film inner join film_actor using(film_id) inner join actor using(actor_id); 查看执行的成本： show status like \u0026#39;last_query_cost\u0026#39;; -- 按照自己预想的规定顺序执行： explain select straight_join film.film_id, film.title, film.release_year, actor.actor_id, actor.first_name, actor.last_name from film inner join film_actor using(film_id) inner join actor using(actor_id); -- 查看执行的成本： show status like \u0026#39;last_query_cost\u0026#39;; 排序优化 ​\t无论如何排序都是一个成本很高的操作，所以从性能的角度出发，应该尽可能避免排序或者尽可能避免对大量数据进行排序。推荐使用利用索引进行排序，但是当不能使用索引的时候，mysql就需要自己进行排序，如果数据量小则再内存中进行，如果数据量大就需要使用磁盘，mysql中称之为filesort。如果需要排序的数据量小于排序缓冲区(show variables like '%sort_buffer_size%';),mysql使用内存进行快速排序操作，如果内存不够排序，那么mysql就会先将树分块，对每个独立的块使用快速排序进行排序，并将各个块的排序结果存放再磁盘上，然后将各个排好序的块进行合并，最后返回排序结果\n单次排序\n先读取查询所需要的所有列，然后再根据给定列进行排序，最后直接返回排序结果；\n此方式只需要一次顺序IO读取所有的数据，而无须任何的随机IO，问题在于查询的列特别多的时候，会占用大量的存储空间，无法存储大量的数据\n两次排序\n第一次数据读取是将需要排序的字段读取出来，然后进行排序；第二次是将排好序的结果按照需要去读取数据行。 这种方式效率比较低，原因是第二次读取数据的时候因为已经排好序，需要去读取所有记录而此时更多的是随机IO，读取数据成本会比较高 两次传输的优势，在排序的时候存储尽可能少的数据，让排序缓冲区可以尽可能多的容纳行数来进行排序操作\n当需要排序的列的总大小超过**max_length_for_sort_data**定义的字节，mysql会选择双次排序，反之使用单次排序，当然，用户可以设置此参数的值来选择排序的方式\n=\u0026gt;执行器 特定类型查询优化 优化COUNT() MYISAM存储引擎在没有where的条件下count(*)最快 近视值，通过EXPLAIN的row取值 更复杂优化，考虑覆盖索引扫描或者增加汇总表 优化关联查询 确保ON后者using字句中有索引，考虑顺序 group by和order by中的表达式中涉及一个表中的列相同排序方式才会用到索引 优化子查询 尽可能通过关联查询代替 优化Limit查询 在很多应用场景中我们需要将数据进行分页，一般会使用limit加上偏移量的方法实现，同时加上合适的orderby 的子句，如果这种方式有索引的帮助，效率通常不错，否则的化需要进行大量的文件排序操作， 还有一种情况，当偏移量非常大的时候，前面的大部分数据都会被抛弃，这样的代价太高，要优化这种查询的话，要么是在页面中限制分页的数量，要么优化大偏移量的性能 优化union查询 mysql总是通过创建并填充临时表的方式来执行union查询，因此很多优化策略在union查询中都没法很好的使用。 经常需要手工的将where、limit、order by等子句下推到各个子查询中，以便优化器可以充分利用这些条件进行优化 用户自定义变量 在查询中混合使用过程化和关系话逻辑的时候，自定义变量会非常有用；用户自定义变量是一个用来存储内容的临时容器，在连接mysql的整个过程中都存在。\n自定义变量使用\nset @one :=1 set @min_actor :=(select min(actor_id) from actor) set @last_week :=current_date-interval 1 week; 自定义变量的限制\n无法使用查询缓存 不能在使用常量或者标识符的地方使用自定义变量，例如表名、列名或者limit子句 用户自定义变量的生命周期是在一个连接中有效，所以不能用它们来做连接间的通信 不能显式地声明自定义变量地类型 mysql优化器在某些场景下可能会将这些变量优化掉，这可能导致代码不按预想地方式运行 赋值符号：=的优先级非常低，所以在使用赋值表达式的时候应该明确的使用括号 使用未定义变量不会产生任何语法错误 使用案例\n优化排名\n-- 1、在给一个变量赋值的同时使用这个变量 select actor_id,@rownum:=@rownum+1 as rownum from actor limit 10; -- 2、查询获取演过最多电影的前10名演员 -- 然后根据出演电影次数做一个排名 select actor_id,count(*) as cnt from film_actor group by actor_id order by cnt desc limit 10; 避免重新查询更新值\n-- 当需要高效的更新一条记录的时间戳，同时希望查询当前记录中存放的时间戳是什么 -- 分开写法 update t1 set lastUpdated=now() where id =1; select lastUpdated from t1 where id =1; -- 自定义变量写法 update t1 set lastupdated = now() where id = 1 and @now:=now(); select @now; 确定取值顺序\n-- 在赋值和读取变量的时候可能是在查询的不同阶段 set @rownum:=0; select actor_id,@rownum:=@rownum+1 as cnt from actor where @rownum\u0026lt;=1; -- 因为where和select在查询的不同阶段执行，所以看到查询到两条记录，这不符合预期 set @rownum:=0; select actor_id,@rownum:=@rownum+1 as cnt from actor where @rownum\u0026lt;=1 order by first_name -- 当引入了order by之后，发现打印出了全部结果， -- 这是因为order by引入了文件排序，而where条件是在文件排序操作之前取值的 -- 解决这个问题的关键在于让变量的赋值和取值发生在执行查询的同一阶段： set @rownum:=0; select actor_id,@rownum as cnt from actor where (@rownum:=@rownum+1)\u0026lt;=1; ","permalink":"http://localhost:1313/posts/mysql%E8%B0%83%E4%BC%98%E7%90%86%E8%AE%BA%E7%AF%87/","summary":"关于MySQL调优理论.","title":"Mysql调优理论篇"},{"content":" 不以规矩，不成方圆\n“Write Once，Run Everywhere”，功归于虚拟机的“规范”\n基本数据类型 u1、u2、u4分别代表占用1字节、2字节、4字节 Class文件结构 自上而下\nClassFile { u4 magic; // 魔术 0xCAFEBABE u2 minor_version;// 次要版本，标识 m u2 major_version;// JDK主要版本,标识 M u2 constant_pool_count;// 常量池个数 cp_info constant_pool[constant_pool_count-1];// 常量池元素数组 下标从1开始 u2 access_flags;// 此类修饰符 u2 this_class;// 此包类或接口路径 如 com/amk/App u2 super_class;// 父类,至少是Object超类 u2 interfaces_count;// 实现接口个数 u2 interfaces[interfaces_count];// 具体的接口名数组 u2 fields_count;// 属性个数 field_info fields[fields_count];// 属性值 u2 methods_count;// 方法个数 method_info methods[methods_count];// 具体方法 u2 attributes_count;// 其他属性计数 attribute_info attributes[attributes_count];// 具体其他属性数组 } 十六进制码 具体看下Class文件\n需要的工具 Sublime 或者 01Editer\n预设知识：图解进制转换\n// 类 public class ClassStructure {} //javac ClassStructure 编译输出 Class文件 public class ClassStructure { // 默认无参构造 public ClassStructure() {} } 通过 Sublime打开,会看到是这样的,这就是Class 十六进制\ncafe babe 0000 0034 0010 0a00 0300 0d07 000e 0700 0f01 0006 3c69 6e69 743e 0100 0328 2956 0100 0443 6f64 6501 000f 4c69 6e65 4e75 6d62 6572 5461 626c 6501 0012 4c6f 6361 6c56 6172 6961 626c 6554 6162 6c65 0100 0474 6869 7301 0010 4c43 6c61 7373 5374 7275 6374 7572 653b 0100 0a53 6f75 7263 6546 696c 6501 0013 436c 6173 7353 7472 7563 7475 7265 2e6a 6176 610c 0004 0005 0100 0e43 6c61 7373 5374 7275 6374 7572 6501 0010 6a61 7661 2f6c 616e 672f 4f62 6a65 6374 0021 0002 0003 0000 0000 0001 0001 0004 0005 0001 0006 0000 002f 0001 0001 0000 0005 2ab7 0001 b100 0000 0200 0700 0000 0600 0100 0000 0400 0800 0000 0c00 0100 0000 0500 0900 0a00 0000 0100 0b00 0000 0200 0c 我们看到\u0026quot;cafe babe\u0026ldquo;开头,这个就是魔数,可以理解为文件类型描述符,从上文得到魔数数据类型是u4,占用4个字节,得到一个码占用4位,下面我们来尝试读取一下\n方法:先看上面的ClassFile中的数据类型u*,在看对应的代表什么\ncafebabe : magic u4 0000: minor_version u2 0 0034: major_version u2 52=4x16^0+3x16^1 表格 0010:constant_pool_count u2 16 \u0026hellip; 以此借助基本数据类型读取进制码 接下来看另一种数据类型读取方法: cp_info,需要借助IDEA\n常量池\njavap -v ClassStructure # 会看到如下结果 Classfile /target/test-classes/ClassStructure.class Last modified 2021年5月9日; size 267 bytes SHA-256 checksum d6a39a3bf56d982b11d79c38256f2f6b2a2f8745c38a4f86440fb9d701f44078 Compiled from \u0026#34;ClassStructure.java\u0026#34; public class ClassStructure # 次版本 minor version: 0 # JDK版本 major version: 52 # 类修饰符 flags: (0x0021) ACC_PUBLIC, ACC_SUPER # 类名 this_class: #2 // ClassStructure # 父类 super_class: #3 // java/lang/Object # 接口 变量 方法 其他属性 计数 interfaces: 0, fields: 0, methods: 1, attributes: 1 # 重点看这儿常量池 Constant pool: # 井号后面是索引 #1 = Methodref 方法 #3(指向3).#13(指向索引13) // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Class #14 // ClassStructure #3 = Class #15 // java/lang/Object #4 = Utf8 \u0026lt;init\u0026gt; #5 = Utf8 ()V #6 = Utf8 Code #7 = Utf8 LineNumberTable #8 = Utf8 LocalVariableTable #9 = Utf8 this #10 = Utf8 LClassStructure; #11 = Utf8 SourceFile #12 = Utf8 ClassStructure.java #13 = NameAndType #4:#5 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #14 = Utf8 ClassStructure #15 = Utf8 java/lang/Object { public ClassStructure(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 4: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this LClassStructure; } SourceFile: \u0026#34;ClassStructure.java\u0026#34; constant_pool_count常量计数后面是常量元素(cp_info),通过规范查到的结构是\ncp_info { u1 tag; u1 info[]; } 所以接下来的u1一个字节0a为tag 10,然后在规定的17个tags得到是\u0026quot;CONSTANT_Methodref\u0026quot;在点击Section这一栏的超链接得到对应的结构为\n// 先知道是什么,后面有宏观解释 CONSTANT_Methodref_info { u1 tag; u2 class_index; // 指向常量池的下一个 类索引 联系上文[Constant pool]#3 u2 name_and_type_index; // 入参:返回类型 索引 练习上文[Constant pool]#15 } 宏观解释无参构造方法:\n// 联系 javap -v 输出结果 Constant pool { u1 tag; 0a // 代表17个Tags中tag为10的CONSTANT_Methodref // #3-\u0026gt;#15-\u0026gt;java/lang/Object 表示类为Object 但是实际类型并不是暂时理解为通用类 // class_index 类为Object占位符,猜想运行时才会转化为具体的类型,TODO 待验证 u2 class_index; 0003 #3 -\u0026gt; [#3 = Class #15] -\u0026gt; [#15 = Utf8 java/lang/Object] // #13-\u0026gt;#13 #4name:#5type -\u0026gt; \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 表示无参构造方法 u2 name_and_type_index; 000d #13 -\u0026gt; [#13 = NameAndType #4:#5]-\u0026gt; [\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V] } 以上读取了 \u0026ldquo;0a00 0300 0d\u0026quot;常量池第一个元素的含义,后面的参照此方法\n总结读取步骤:\nu1 查tags表 链接Section栏的超链接查看具体的结构字节数 带着字节数索引在javap -v 总常量池[Constant pool]总向后推进 最后介绍个IDEA插件:jclasslib Bytecode Viewer代替Javap -v 更加直观\n插件参构造表示方式 参考:Oracle Class文件结构\nNext：用Java Buffer解析字节码\n","permalink":"http://localhost:1313/posts/%E6%B5%85%E5%85%A5class%E5%AD%97%E8%8A%82%E7%A0%81/","summary":"关于Class字节码.","title":"浅入Class字节码"},{"content":"实践得出结论 小程序™： /** * @author Chunming Liu */ public class HeapOOMTest { public static void main(String[] args) { new Thread ( () -\u0026gt; { ArrayList\u0026lt;byte[]\u0026gt; bytes = new ArrayList\u0026lt;\u0026gt; (); while (true) { System.out.println ( \u0026#34;[\u0026#34; + LocalDateTime.now () + \u0026#34;] \u0026#34; + Thread.currentThread () ); bytes.add ( new byte[1024 * 1024] ); try { Thread.sleep ( 1000 ); } catch (InterruptedException e) { e.printStackTrace (); } } } ).start (); new Thread ( () -\u0026gt; { while (true) { System.out.println ( LocalDateTime.now () + \u0026#34;==\u0026#34; + Thread.currentThread () ); try { Thread.sleep ( 1000 ); } catch (InterruptedException e) { e.printStackTrace (); } } } ).start (); } } 运行之前添加JVM参数 -Xms16m -Xmx32m\n通过运行期间发生了 OOM但是可以出程序还是在正常运行 Jconsole监控堆信息 JVM运行时内存情况 结论 触发堆异常不会影响其他线的运行，通过VM的内存情况，可以看出第一次发生的GC会将堆信息移动到老年代，后面的GC伊甸区活动，猜测和GC的策略有关（当前的GC策略：ParScav:MSC）\n","permalink":"http://localhost:1313/posts/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E5%8F%91%E7%94%9Foom%E5%85%B6%E4%BB%96%E7%BA%BF%E7%A8%8B%E4%B8%8D%E4%BC%9A%E5%81%9C%E6%AD%A2/","summary":"关于多线程下发生OOM其他线程不会停止.","title":"多线程下发生OOM其他线程不会停止"},{"content":"C、C++、Java 操作系统层面 C、C++直接在操作系统上执行\nJava需要编程编译成字节码基于JVM去执行，而JVM是运行在操作系统与C\\C++平级\n:computer:JVM虚拟机:可以理解为模拟的操作系统，独立在操作系统之上的一个拥有独立内存的子系统\n最初是JVM是将字节码解释为C语言去执行，后来发现这样的性能特别低，现在直接解释为机器语言提高效率\n语言关系 为了设计符合人类思想行为的高级语言，C语言面向过程，C++面向对象，符合人类思想，由于是直接对操作编程容易导致系统的安全性问题，需要Coder自己手动管理物理内存，复杂的指针语法，而Java语言解决了C++的这些安全问题，并且更加的如意上手 跨平台性 C、C++在同一个功能API每个操作系统中各不相同，程序无法在其他环境中直接执行 Java是运行在JVM上的，统一了JVM的输入源规范根据不同的平台解释成对应的平台的API，即实现了“write once，run everywhere” 两种编程思想 面向过程 关注的是数据的流向过程 面向对象 关注的是对象之间关系的交互 面向对象解决问题的步骤：首先对事件中的对象进行OOA，分析各个对象的行为及属性-\u0026gt;第二步骤对事件中对象之间的交互关系进行合理的设计OOD-\u0026gt;最后对合理的设计进行编码实现OOP\n三大特性 封装 对象本质进行包装，通过public、private、protected关键字语法去实现，保护对象的数据安全 继承 古代君王世袭制，Java所有类都默认继承超类Object 多态 猿人不断进化成人类，人类不仅继承了猿人的特征，还具有独立的思考 数据类型 基本数据类型 整型：\nbyte:1 short:2 int:4 long:8 char:2(UTF-16) 浮点型：\nfloat:4 double:8 特殊型：\nboolean：true和false\nretrunadress：JVM规范定义的基本数据类型，用来标识finally和return的\n包装类 Integer、Double、Long 引用型 接口，对象 JVM中默认locals中一个槽为32位\n","permalink":"http://localhost:1313/posts/java-core/","summary":"关于Java核心.","title":"Java Core"},{"content":"个人信息 156****8852｜niklechunming@163.com｜感兴趣：物联网、AIGC\n个人优势 5年一线后端开发经验，熟悉公有云架构，微服务架构项目完整开发流程;在多个项目中担任主程，项目经历包含 物联网边缘网关、AI分析、汽⻋后市场经销商CRM，经销商运营微信小程序等;有产品意识，以用户的⻆度去设计实现功能;持续关注学习LLM应用端场景落地、Agent、RAG、Fine-tuning等技术，自主实现过Flow Agent、本地知识库、RAG搜索服务等；目前也在积极参与开源共建AI社区做一些贡献。\n积累的 技术栈 有：\n熟练掌握 Web技术栈，使用GO/Java/Python进行后端服务开发，深入理解语言内部运行机制，也在学习C/C++和阅读流媒体服务器如ZLMediaKit、WebRTC等，尝试过混合JNI、JNA、CGO，有一定的前端工程能力包含JavaScript、HTML、CSS、JQuery等； 熟练掌握网络和多线程编程，深入理解NIO、BIO、AIO以及goroutine、chain等技术概念； 熟悉 物联网常见云-边-端开发部署架构，以及相关技术框架选型， 熟悉 AI算法边缘硬件落地工作流，有yolo算法部署瑞芯微NPU开发版开发部署经验； 熟悉 rtsp、gb28181、ws-flv、rtmp等流媒体协议以及流媒体服务服务搭建，自主实现过rtsp客户端、SIP服务器，同时也在阅读ZLMediaKit、Monibuca等开源项目 熟悉 JVM工具排查日志工具，如事故保留和处理、Arthas、jcmd、jmap 、mat等工具 熟悉 关系型数据库 MySQL ，对 MySQL 调优经验有一定经验，理解其索引实现原理 孰悉 常见 Redis 核心数据结构，了解 Redis 哨兵和集群架构及并发场景的问题如缓存雪崩，缓存穿透等并对其数据结构和持久化机制有一定理解 熟悉 常见分布式场景的技术难题，比如分布式锁，分布式事务，分布式定时任务等 掌握 Spring , Mybatis , SpringMVC , Spring boot 等框架并研究过它们的核心原理 熟练 使用 Spring Cloud Netfix 以及衍生代 Spring Cloud Alibaba 微服务架构，能独立搭建一套微服务开发基础设施 熟练 合理使用 RocketMQ、Kafka、RabbitMQ 消息中间件，对各种消息通信场景的疑难问题有一定的解决能力，比如消息丢失、消息重复消费、消息顺序消费、大规模消息积压问题。 熟悉 LInux环境部署和应用异常排查及解决，如系统资源监控、栈异常信息、日志检索、日志检索 熟悉 Shell、Python脚本语言，如Shell根据应用部署编写，Python处理报表附件整理 熟悉 各种项目管理工具，如 Jenkins、Docker、Maven、 Gitlab 等 熟练 使用 IntelliJ IDEA 开发．熟悉 Git 和 SVN 代码版本管理工具 工作经历 23/07-至今：个人工作室｜项目技术负责人 “项目负责人 \u0026amp;\u0026amp; 后端开发，负责团队搭建、技术选型、培训分享和项目的开发等工作”\n项目名称： 底盘智能数字化平台（中国汽车工程研究院股份有限公司）\n项目概述： 平台支持底盘性能开发，系统贯穿整个底盘开发阶段，包含急架K\u0026amp;C数和质心转动惯量数据、路车操稳数据和驾乘性能主观评价数据可视化。能够实现快速的车型数据、指标范围搜索，多车型数据对比和分析、报告的自动生成、用户权限自定义控制\n项目技术栈： 以Java语言和SpringBoot框架为基础，JPA映射操作数据，MySQL持久化存储数据及Redis的Hash、String数据结构存储临时数据提高响应，数据报表导出工具POI，Nginx权重负载均衡，Minio对象存储，Matlab编译引擎执行实验脚本\n职责与成就：\n负责项目需求分析，编写接口文档，确保后续技术团队对项目目标有清晰的理解 负责项目整体架构设计，技术选型，保证系统具有高可用性、可扩展性和易维护性 负责权限模块设计与实现，基于 RBAC 模型完成用户与权限的解耦，构建用户、角色、权限；内置超级管理员根据需要管理用户账户和权限的管理 负责Minio对象存储、Mysql、Redis、Nginx最小单元开发环境搭建和部署 负责Matlab脚本在线编译运行方案设计和实现，基于Matlab支持的mcc设计编译脚本，基于Matlab的Javabuilder构建脚本执行器，自定义实现类加载器管理试验脚本 负责项目性能系统优化，解决频繁FullGC问题，优化接口数据传输带宽 22/03-23/07：北京中科长鹰科技有限公司（物联网电力） “高级后端工程师，负责公司内部项目的开发和维护，系统模块设计和评审，培训组织等工作。”\n项目名称： EdgeBox边缘智能网关\n项目概述： EdgeBox 边缘智能网关是一款面向电力、煤矿行业等应用场景，为用户提供环境数据实时分析、高清视频监控接入、视频智能分析与告警、远程设备控制的智能化一体机设备\n项目技术栈： 基于Go语言和EdgeX Foundry框架构建，Sqlite元数据存储，Grom操作数据库，MQTT北上通信和数据流转，eKuiper规则引擎，Influx存储传感器数据，Python语言实现AI分析模块\n职责与成就：\n参与完善需求设计、需求评审、立项评审等\n负责网关支持GB28181协议，设计和实现SIP信令服务器，支持设备 注册、注销、实时监控、回放、云台控制\n负责网关支持Onvif协议，设计和实现设备 实时监控、回放、云台控制\n设计与实现RTSP客户端，支持拉流并转发、回放控制\n负责网关AI分析能力实现，支持人脸识别、人体检测、周界入侵检测、车辆识别等分析能力\n项目名称： IOT-Frame（云平台-网关）\n项目概述： 构建各种电力站房的视频，安防，环境，联动等设备监控业务平台\n项目技术栈： JDK8、SpringCloud、SpringBoot、Mysql、Influx、MQTT、SOFABoot、Influx、Sqlite、JPA、Mybatis-plus、Docker、Kuboard\n职责描述：\n参与完善需求设计、需求评审、立项评审等\n负责网关支持GB28181协议，设计和实现SIP信令服务器，支持设备 注册、注销、实时监控、回放、云台控制\n负责网关支持Onvif协议，设计和实现设备 实时监控、云台控制\n19/08-22/01：北汽福田汽车股份有限公司（汽车生产） “Java开发工程师，负责国内外经销商系统的开发和维护工作。”\n项目名称： 经销商平台-ICM爱行销（双语）\n项目概述： 经销商自己手动统计上报绩效，管理层无法统计快速统计经销商业务绩效，经销商通过本系统维护客户、线索、活动、交付情况，管理层不仅能分析经销商情况，同时可通过线索池、行销活动下发经销商任务及对经销商的交付进行政策兑现\n项目技术栈： 以Java语言和Spring Cloud、SpringBoot框架为基础，JPA映射操作数据，Eureka注册中心，Hystrix服务通信熔断，OpenFeign服务之间通信，MySQL持久化存储、Redis运行时数据缓存，POI数据表导出工具，Python脚本处理附件打包并下载\n系统难点：\n车库信息查询涉及表结构复杂，查询慢；\n分析表结构和查询条件梳理及原SQL实现，减少子查询，优化SQL，响应提升60%，由18s下降到3-4s内.\n线索状态同步节点多，同步状态时序可能会乱（网络、同步中断）；\nHystrix熔断持久化同步异常，设计实现自省定时任务，定时任务根据预设规则检查同步时序并补偿，提升系统稳定性，减少人工补偿排错.\n数据报表涉及表复杂，响应慢；\n凌晨统一定时多线程处理报表任务，处理完成附件上传OSS下载链接持久化，提高响应，毫秒级响应.\n业务附件集合大，涉及服务多，重复代码多，响应慢；\n通用API设计和任务线程池，任务式触发，任务完成打包并上传OSS下载链接持久化，短信通知经销商，可视化任务状态，减少源代码的重复性，任务完成率提升50%.\n基础属性展示需要兼容多语言；\n请求体header协定，设计字典表结构，统一消息处理，配置相关拦截器构建local（scope=request），消息、字典根据header响应对应的语言，避免整体重构，增加扩展性，缩短开发周期，提前半月完成\n项目名称： 智慧云商城\n项目概述： 为经销商制作线上店铺，通过小程序方便推广，从而产生留资信息转为爱行销线索\n项目技术栈：以Java语言和SpringBoot框架基础，Mybatis-plus映射操作数据，MySQL持久化存储数据及Redis的Hash、String数据结构存储临时数据提高响应，数据报表导出工具POI，Nginx权重负载均衡\n系统难点：\n数据来源第三方系统，无法感知第三方数据修改；\n每次打开PC端去检查校验数据是否需要更新，懒更新小程序的数据，提高了数据的准确度和实时性.\n统计埋点多，不易维护；\nAOP实现切点，通过灵活配置切点，减少源代码侵入，定期维度统计结果并持久化，提升响应速度60%.\n教育经历 西安交通大学-计算机科学与技术-本科 ","permalink":"http://localhost:1313/about/","summary":"\u003ch2 id=\"个人信息\"\u003e个人信息\u003c/h2\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"\"\u003e156****8852\u003c/a\u003e｜niklechunming@163.com｜\u003ca href=\"\"\u003e感兴趣：\u003cem\u003e物联网、AIGC\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"个人优势\"\u003e个人优势\u003c/h2\u003e\n\u003chr\u003e\n\u003cp\u003e5年一线后端开发经验，熟悉公有云架构，微服务架构项目完整开发流程;在多个项目中担任主程，项目经历包含 物联网边缘网关、AI分析、汽⻋后市场经销商CRM，经销商运营微信小程序等;有产品意识，以用户的⻆度去设计实现功能;持续关注学习LLM应用端场景落地、Agent、RAG、Fine-tuning等技术，自主实现过Flow Agent、本地知识库、RAG搜索服务等；目前也在积极参与开源共建AI社区做一些贡献。\u003c/p\u003e\n\u003cp\u003e积累的 \u003cstrong\u003e技术栈\u003c/strong\u003e 有：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e熟练掌握\u003c/strong\u003e Web技术栈，使用GO/Java/Python进行后端服务开发，深入理解语言内部运行机制，也在学习C/C++和阅读流媒体服务器如ZLMediaKit、WebRTC等，尝试过混合JNI、JNA、CGO，有一定的前端工程能力包含JavaScript、HTML、CSS、JQuery等；\u003c/li\u003e\n\u003cli\u003e熟练掌握网络和多线程编程，深入理解NIO、BIO、AIO以及goroutine、chain等技术概念；\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e 物联网常见云-边-端开发部署架构，以及相关技术框架选型，\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e AI算法边缘硬件落地工作流，有yolo算法部署瑞芯微NPU开发版开发部署经验；\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e rtsp、gb28181、ws-flv、rtmp等流媒体协议以及流媒体服务服务搭建，自主实现过rtsp客户端、SIP服务器，同时也在阅读ZLMediaKit、Monibuca等开源项目\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e JVM工具排查日志工具，如事故保留和处理、Arthas、jcmd、jmap 、mat等工具\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e 关系型数据库 MySQL ，对 MySQL 调优经验有一定经验，\u003cstrong\u003e理解\u003c/strong\u003e其索引实现原理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e孰悉\u003c/strong\u003e 常见 Redis 核心数据结构，了解 Redis 哨兵和集群架构及并发场景的问题如缓存雪崩，缓存穿透等并对其数据结构和持久化机制有一定理解\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e 常见分布式场景的技术难题，比如分布式锁，分布式事务，分布式定时任务等\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e掌握\u003c/strong\u003e Spring , Mybatis , SpringMVC , Spring boot 等框架并研究过它们的核心原理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟练\u003c/strong\u003e 使用 Spring Cloud Netfix 以及衍生代 Spring Cloud Alibaba 微服务架构，能独立搭建一套微服务开发基础设施\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟练\u003c/strong\u003e 合理使用 RocketMQ、Kafka、RabbitMQ 消息中间件，对各种消息通信场景的疑难问题有一定的解决能力，比如消息丢失、消息重复消费、消息顺序消费、大规模消息积压问题。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e LInux环境部署和应用异常排查及解决，如系统资源监控、栈异常信息、日志检索、日志检索\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e Shell、Python脚本语言，如Shell根据应用部署编写，Python处理报表附件整理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟悉\u003c/strong\u003e 各种项目管理工具，如 Jenkins、Docker、Maven、 Gitlab 等\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熟练\u003c/strong\u003e 使用 IntelliJ IDEA 开发．熟悉 Git 和 SVN 代码版本管理工具\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"工作经历\"\u003e工作经历\u003c/h2\u003e\n\u003chr\u003e\n\u003ch3 id=\"2307-至今个人工作室项目技术负责人\"\u003e23/07-至今：个人工作室｜项目技术负责人\u003c/h3\u003e\n\u003cp\u003e“项目负责人 \u0026amp;\u0026amp; 后端开发，负责团队搭建、技术选型、培训分享和项目的开发等工作”\u003c/p\u003e","title":"About"},{"content":" github.com/nanxiaobei lee.so ","permalink":"http://localhost:1313/contact/","summary":"\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/nanxiaobei\"\u003egithub.com/nanxiaobei\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://lee.so\"\u003elee.so\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Contact"},{"content":"流媒体网络协议系列：RTP 概述 RFC3550\nRTP协议 RTP-视频流 RTP-h264 RTP-音频流 RTP-AAC ","permalink":"http://localhost:1313/posts/%E6%B5%81%E5%AA%92%E4%BD%93%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E7%B3%BB%E5%88%97rtp/","summary":"\u003ch1 id=\"流媒体网络协议系列rtp\"\u003e流媒体网络协议系列：RTP\u003c/h1\u003e\n\u003ch2 id=\"概述\"\u003e概述\u003c/h2\u003e\n\u003cp\u003eRFC3550\u003c/p\u003e\n\u003ch2 id=\"rtp协议\"\u003eRTP协议\u003c/h2\u003e\n\u003ch2 id=\"rtp-视频流\"\u003eRTP-视频流\u003c/h2\u003e\n\u003ch3 id=\"rtp-h264\"\u003eRTP-h264\u003c/h3\u003e\n\u003ch2 id=\"rtp-音频流\"\u003eRTP-音频流\u003c/h2\u003e\n\u003ch3 id=\"rtp-aac\"\u003eRTP-AAC\u003c/h3\u003e","title":""},{"content":"","permalink":"http://localhost:1313/tags/","summary":"tags","title":"Tags"}]